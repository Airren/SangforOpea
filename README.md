# Intel Arc GPU ç¦»çº¿éƒ¨ç½²å¤§è¯­è¨€æ¨¡å‹æŒ‡å—

## å‰ç½®æ¡ä»¶

- **æ“ä½œç³»ç»Ÿ**ï¼šUbuntu 24.04 (x86_64)
- **GPU**ï¼šIntel Arc GPU
- **æƒé™**ï¼šç¡®ä¿å…·å¤‡ `sudo` æƒé™
- **å®‰è£…åŒ…**ï¼šé€šè¿‡Intelçš„IPSä¸‹è½½ç¦»çº¿éƒ¨ç½²èµ„æºåŒ… Intel_Arc_LLM_Offline_Deployment.tar.gz

---

## **å‡†å¤‡å·¥ä½œï¼šä¸‹è½½è§£å‹ç¦»çº¿éƒ¨ç½²èµ„æºåŒ…**

ä¸‹è½½ç¦»çº¿éƒ¨ç½²èµ„æºåŒ…ï¼Œå¤åˆ¶èµ„æºåŒ…åˆ°ç›¸åº”çš„æœºå™¨ï¼Œå¹¶è§£å‹ï¼š

```bash

# è¯·æ ¹æ®å®é™…Intelæä¾›çš„ä¸‹è½½æ–¹å¼ä¸‹è½½ç¦»çº¿å®‰è£…åŒ…
wget https://download.01.org/Intel_Arc_LLM_Offline_Deployment.tar.gz 

tar -xvf Intel_Arc_LLM_Offline_Deployment.tar.gz
```

## **ç¬¬ä¸€æ­¥ï¼šç¦»çº¿éƒ¨ç½²å®‰è£… Docker**

### 1.1 ç¦»çº¿å®‰è£… Docker

å°†æ–‡ä»¶ä¼ è¾“åˆ°ç›®æ ‡æœºå™¨ï¼Œæ‰§è¡Œå®‰è£…ï¼š

```bash
cd Intel_Arc_LLM_Offline_Deployment
bash install_docker.sh
```

### 1.2 å¯ä»¥æ‰‹åŠ¨éªŒè¯ Docker (å¯è·³è¿‡)

```bash
docker --version
docker-compose --version
```

### **æ³¨æ„äº‹é¡¹**

- ç¡®ä¿ Docker Daemon æ­£å¸¸å¯åŠ¨ï¼Œ`sudo systemctl status docker`ã€‚
- å¯è€ƒè™‘å°†æ™®é€šç”¨æˆ·åŠ å…¥ `docker` ç»„ï¼Œå…å»é¢‘ç¹è¾“å…¥ sudoï¼š `sudo usermod -aG docker $USER`

---

## **ç¬¬äºŒæ­¥ï¼šä½¿ç”¨ Docker Compose éƒ¨ç½² LLM æœåŠ¡**

### 2.1 ä¿®æ”¹å¹¶è®¾ç½®ç¯å¢ƒå˜é‡

ç¼–è¾‘ `set_env.sh` æ–‡ä»¶ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡ï¼š

#### 2.1.1 æ ¹æ®å®é™…GPUæ˜¾å­˜æƒ…å†µï¼Œé€‰æ‹©æ¨¡å‹

ç›®å‰ç¦»çº¿å®‰è£…åŒ…æä¾›çš„æ¨¡å‹æœ‰ï¼š

| æ¨¡å‹åç§°                        | æ˜¾å­˜è¦æ±‚ | ç±»åˆ«  |
|-----------------------------|------|-----|
| Qwen/Qwen2.5-7B-Instruct    | 8GB  | LLM |
| Qwen/Qwen2.5-7B-OpenAI      | 8GB  | LLM |
| Qwen/Qwen2.5-7B-OpenWebText | 8GB  | LLM |
| deepseekai/gpt3-175b        | 16GB | LLM |
| deepseekai/gpt3-175b-turbo  | 16GB | LLM |

```bash
source set_env.sh
```

### 2.1 åŠ è½½ç¦»çº¿é•œåƒå¹¶å¯åŠ¨LLMæœåŠ¡

```bash
bash start_llm.sh
```

### **æ³¨æ„äº‹é¡¹**

- ç¡®ä¿ Docker Compose æ–‡ä»¶ä¸­çš„ `capabilities: ["gpu"]` æ­£ç¡®é…ç½® Intel GPU åŠ é€Ÿã€‚
- å¦‚æœé•œåƒåŸºäº PyTorch æˆ–è€… TensorFlowï¼Œéœ€ç¡®è®¤æ˜¯å¦åŒ…å« Intel GPU ä¼˜åŒ–ç‰ˆåº“ï¼ˆå¦‚ `intel-extension-for-pytorch`ï¼‰ã€‚
- åœ¨å®¹å™¨å†…ç¡®è®¤ GPU å¯è§ï¼š`docker exec -it <container_id> bash -c "ls /dev/dri"`ã€‚

---

## **ç¬¬ä¸‰æ­¥ï¼šéªŒè¯ LLM æœåŠ¡**

### 3.1 ä½¿ç”¨ cURL è¿›è¡Œç®€å•æ¥å£éªŒè¯

å°†æ¨¡å‹æœåŠ¡å¯åŠ¨åï¼Œå¯ä»¥ä½¿ç”¨ cURL å‘é€è¯·æ±‚ï¼ŒéªŒè¯æœåŠ¡æ˜¯å¦æ­£å¸¸ã€‚
æ›¿æ¢ `model` å’Œ `prompt` å‚æ•°ï¼Œå‘é€è¯·æ±‚ï¼š

```bash
curl http://localhost:8000/v1/completions \
     -H "Content-Type: application/json" \
     -d '{"model": "Qwen/Qwen2.5-7B-Instruct",
          "prompt": "è¯·ä»‹ç»ä½ è‡ªå·±",
          "max_tokens": 520
         }'
```

### 3.2 æŸ¥çœ‹ Docker æ—¥å¿—æ’æŸ¥ (å¯é€‰)

å¦‚æœè¯·æ±‚å¤±è´¥ï¼Œæ’æŸ¥æ—¥å¿—ï¼š

```bash
docker logs <container_id>
```

### **æ³¨æ„äº‹é¡¹**

- ç¡®ä¿ LLM æœåŠ¡é…ç½®äº†æ­£ç¡®çš„ç«¯å£æ˜ å°„ã€‚
- ç¡®ä¿å®¹å™¨å†…æ¨ç†æ¨¡å‹æ­£å¸¸åŠ è½½ï¼Œæ˜¾å­˜å……è¶³ã€‚
- å¦‚æœæ€§èƒ½å¼‚å¸¸ï¼Œè€ƒè™‘è°ƒæ•´ç­‰å‚æ•°ã€‚

---

## **æ€»ç»“**

å®Œæˆä»¥ä¸Šä¸‰æ­¥ï¼Œæ‚¨åº”è¯¥èƒ½åœ¨ Intel Arc GPU ä¸Šç¦»çº¿è¿è¡Œ LLM æ¨¡å‹æœåŠ¡äº† ğŸ‰ã€‚


